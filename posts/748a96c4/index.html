<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="theme-color" content="#6200ee"><meta name="author" content="Giyn"><meta name="copyright" content="Giyn"><meta name="generator" content="Hexo 5.1.1"><meta name="theme" content="hexo-theme-yun"><title>决策树算法原理 | Giyn's Blog</title><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap" media="none" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/star-markdown-css@0.1.19/dist/yun/yun-markdown.min.css"><script src="//at.alicdn.com/t/font_1140697_stqaphw3j4.js" async></script><script src="https://cdn.jsdelivr.net/npm/scrollreveal/dist/scrollreveal.min.js" defer></script><script>document.addEventListener("DOMContentLoaded", () => {
  [".post-card",".post-content img"].forEach((target)=> {
    ScrollReveal().reveal(target);
  })
});
</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/auto-render.min.js"></script><script>document.addEventListener("DOMContentLoaded", function() {
  renderMathInElement(document.body, {
    delimiters: [
      {left: "$$", right: "$$", display: true},
      {left: "$", right: "$", display: false},
      {left: "\\(", right: "\\)", display: false},
      {left: "\\[", right: "\\]", display: true}
    ]
  });
});</script><link rel="shortcut icon" type="image/svg+xml" href="/Giyn.ico"><link rel="mask-icon" href="/Giyn.ico" color="#6200ee"><link rel="alternate icon" href="/yun.ico"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="preload" href="/js/utils.js" as="script"><link rel="preload" href="/js/hexo-theme-yun.js" as="script"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><link rel="stylesheet" href="/css/hexo-theme-yun.css"><link rel="alternate" href="/atom.xml" title="Giyn's Blog" type="application/atom+xml"><script id="yun-config">
    const Yun = window.Yun || {};
    window.CONFIG = {"root":"/","title":"许继元的博客","version":"1.0.0","anonymous_image":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/avatar/none.jpg","say":{"api":"/data/sentences.json"},"local_search":{"path":"/search.xml"},"fireworks":{"colors":["102, 167, 221","62, 131, 225","33, 78, 194"]}};
  </script><script src="//at.alicdn.com/t/font_1140697_stqaphw3j4.js" async></script><meta name="description" content="什么是决策树？决策树是一种逻辑简单的机器学习算法，可用作分类，也可用作回归，属于监督学习（Supervised learning）。 决策树的模型表达式 f(x) 很难被写出，却很容易被画出 决策树是一种树形结构： 树形结构：①结点+有向边②没有回路，根结点为始、叶子结点为终    或者这么画：    根节点：包含样本的全集 内部节点：对应特征属性测试 叶节点：代表决策的结果 决策树学习的步骤：">
<meta property="og:type" content="article">
<meta property="og:title" content="决策树算法原理">
<meta property="og:url" content="http://giyn.work/posts/748a96c4/index.html">
<meta property="og:site_name" content="Giyn&#39;s Blog">
<meta property="og:description" content="什么是决策树？决策树是一种逻辑简单的机器学习算法，可用作分类，也可用作回归，属于监督学习（Supervised learning）。 决策树的模型表达式 f(x) 很难被写出，却很容易被画出 决策树是一种树形结构： 树形结构：①结点+有向边②没有回路，根结点为始、叶子结点为终    或者这么画：    根节点：包含样本的全集 内部节点：对应特征属性测试 叶节点：代表决策的结果 决策树学习的步骤：">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200424102622422.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200424102640336.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200424105433997.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200424110907282.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200424111253350.png">
<meta property="article:published_time" content="2020-09-28T05:54:27.000Z">
<meta property="article:modified_time" content="2020-10-07T13:34:09.601Z">
<meta property="article:author" content="Giyn">
<meta property="article:tag" content="MachineLearning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/20200424102622422.png"><script src="/js/ui/mode.js"></script><link id="light-prism-css" rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1.20.0/themes/prism.css" media="(prefers-color-scheme: light)"><link id="dark-prism-css" rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1.20.0/themes/prism-tomorrow.css" media="(prefers-color-scheme: dark)"></head><body><script defer src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script defer src="/js/ui/fireworks.js"></script><canvas class="fireworks"></canvas><div class="container"><a class="sidebar-toggle hty-icon-button" id="menu-btn"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><div class="sidebar-toggle sidebar-overlay"></div><aside class="sidebar"><script src="/js/sidebar.js"></script><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc hty-icon-button sidebar-nav-active" data-target="post-toc-wrap" title="Table of Contents"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-list-ordered"></use></svg></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="Overview"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-passport-line"></use></svg></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info mickey-mouse"><a class="site-author-avatar" href="/about/" title="Giyn"><img width="96" loading="lazy" src="/images/avatar.png" alt="Giyn"></a><div class="site-author-name"><a href="/about/">Giyn</a></div><a class="site-name" href="/about/site.html">Giyn's Blog</a><sub class="site-subtitle"></sub><div class="site-desciption"></div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="Home"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-home-4-line"></use></svg></span></a><div class="site-state-item"><a href="/archives/" title="Archives"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-archive-line"></use></svg></span><span class="site-state-item-count">59</span></a></div><div class="site-state-item"><a href="/categories/" title="Categories"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-2-line"></use></svg></span><span class="site-state-item-count">20</span></a></div><div class="site-state-item"><a href="/tags/" title="Tags"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="site-state-item-count">40</span></a></div><a class="site-state-item hty-icon-button" href="/about/"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-open-arm-line"></use></svg></span></a></nav><hr style="margin-bottom:0.5rem"><div class="links-of-author"><a class="links-of-author-item hty-icon-button" rel="noopener" href="/atom.xml" title="RSS" target="_blank" style="color:orange"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-rss-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://github.com/Giyn" title="GitHub" target="_blank" style="color:#181717"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-github-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="mailto:giyn.jy@gmail.com" title="E-Mail" target="_blank" style="color:#8E71C1"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-mail-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="http://wpa.qq.com/msgrd?v=3&amp;uin=490601115&amp;site=qq&amp;menu=yes" title="QQ" target="_blank" style="color:#12B7F5"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-qq-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://space.bilibili.com/443380473" title="bilibili" target="_blank" style="color:#FF8EB3"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-bilibili-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://twitter.com/jiyuan_xu" title="Twitter" target="_blank" style="color:#1da1f2"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-twitter-line"></use></svg></a></div><br><a class="links-item hty-icon-button" id="toggle-mode-btn" href="javascript:;" title="Mode" style="color: #f1cb64"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-contrast-2-line"></use></svg></a></div><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%86%B3%E7%AD%96%E6%A0%91%EF%BC%9F"><span class="toc-number">1.</span> <span class="toc-text">什么是决策树？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E6%98%AF%E4%B8%80%E7%A7%8D%E6%A0%91%E5%BD%A2%E7%BB%93%E6%9E%84%EF%BC%9A"><span class="toc-number">1.1.</span> <span class="toc-text">决策树是一种树形结构：</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%A0%91%E5%BD%A2%E7%BB%93%E6%9E%84%EF%BC%9A"><span class="toc-number">1.1.0.0.1.</span> <span class="toc-text">树形结构：</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%AD%A5%E9%AA%A4%EF%BC%9A"><span class="toc-number">1.2.</span> <span class="toc-text">决策树学习的步骤：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E5%88%86%E8%A3%82%EF%BC%88%E5%86%B3%E7%AD%96%EF%BC%89%EF%BC%9A"><span class="toc-number">1.3.</span> <span class="toc-text">决策树的分裂（决策）：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%AF%E5%8F%91%E5%BC%8F%E7%AE%97%E6%B3%95%EF%BC%9A"><span class="toc-number">1.4.</span> <span class="toc-text">启发式算法：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%80%E4%BC%98%E5%86%B3%E7%AD%96%EF%BC%9A"><span class="toc-number">1.5.</span> <span class="toc-text">最优决策：</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%B0%B1%E6%98%AF%E6%9D%A1%E4%BB%B6%E7%86%B5"><span class="toc-number">1.5.1.</span> <span class="toc-text">决策树的损失函数就是条件熵</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E7%9A%84%E5%88%86%E7%B1%BB%EF%BC%9A"><span class="toc-number">1.6.</span> <span class="toc-text">决策树算法的分类：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9%EF%BC%9A"><span class="toc-number">1.7.</span> <span class="toc-text">决策树算法的优缺点：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF-ID3-%E7%AE%97%E6%B3%95%EF%BC%9F"><span class="toc-number">2.</span> <span class="toc-text">什么是 $ID3$ 算法？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A"><span class="toc-number">2.1.</span> <span class="toc-text">信息增益</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ID3-%E7%AE%97%E6%B3%95%E7%9A%84%E6%AD%A5%E9%AA%A4%EF%BC%9A"><span class="toc-number">2.2.</span> <span class="toc-text">$ID3$ 算法的步骤：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF-C4-5-%E7%AE%97%E6%B3%95%EF%BC%9F"><span class="toc-number">3.</span> <span class="toc-text">什么是 $C4.5$ 算法？</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#C4-5-%E7%AE%97%E6%B3%95%E6%98%AF%E5%9F%BA%E4%BA%8E-ID3-%E7%AE%97%E6%B3%95%E7%9A%84%E6%94%B9%E8%89%AF%EF%BC%8C-C4-5-%E7%AE%97%E6%B3%95%E4%B8%8D%E7%9B%B4%E6%8E%A5%E4%BD%BF%E7%94%A8%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%EF%BC%8C%E8%80%8C%E6%98%AF%E4%BD%BF%E7%94%A8%E2%80%9C%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E7%8E%87%E2%80%9D%E6%9D%A5%E9%80%89%E6%8B%A9%E6%9C%80%E4%BC%98%E5%88%92%E5%88%86%E5%B1%9E%E6%80%A7%E3%80%82"><span class="toc-number">3.0.0.0.1.</span> <span class="toc-text">$C4.5$ 算法是基于 $ID3$ 算法的改良，$C4.5$ 算法不直接使用信息增益，而是使用“信息增益率”来选择最优划分属性。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E-ID3-%E7%AE%97%E6%B3%95%E7%9A%84%E4%BC%98%E5%8C%96%EF%BC%9A"><span class="toc-number">3.0.0.0.2.</span> <span class="toc-text">基于 $ID3$ 算法的优化：</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E7%8E%87"><span class="toc-number">3.1.</span> <span class="toc-text">信息增益率</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#C4-5-%E7%9A%84%E4%B8%8D%E8%B6%B3%E4%B9%8B%E5%A4%84%EF%BC%9A"><span class="toc-number">3.1.0.0.1.</span> <span class="toc-text">$C4.5$ 的不足之处：</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CART-%E7%AE%97%E6%B3%95"><span class="toc-number">4.</span> <span class="toc-text">$CART$ 算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E5%B0%BC%E6%8C%87%E6%95%B0"><span class="toc-number">4.1.</span> <span class="toc-text">基尼指数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#CART-%E7%AE%97%E6%B3%95%E4%B8%AD%E4%B8%BB%E8%A6%81%E5%88%86%E4%B8%BA%E4%B8%A4%E4%B8%AA%E6%AD%A5%E9%AA%A4"><span class="toc-number">4.1.1.</span> <span class="toc-text">$CART$ 算法中主要分为两个步骤</span></a></li></ol></li></ol></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="post-block" itemscope itemtype="https://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://giyn.work/posts/748a96c4/"><span hidden itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="name" content="Giyn"><meta itemprop="description"></span><span hidden itemprop="publisher" itemscope itemtype="https://schema.org/Organization"><meta itemprop="name" content="Giyn's Blog"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">决策树算法原理<a class="post-edit-link" href="https://github.com/Giyn/giyn.github.io/tree/hexo/source/_posts/决策树算法原理.md" target="_blank" title="Edit this post" rel="noopener"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-edit-line"></use></svg></a></h1><div class="post-meta"><div class="post-time" style="display:block"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-line"></use></svg></span> <span class="post-meta-icon-text">Posted on</span> <time title="Created: 2020-09-28 13:54:27" itemprop="dateCreated datePublished" datetime="2020-09-28T13:54:27+08:00">2020-09-28</time><span class="post-meta-divider">-</span><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-2-line"></use></svg></span> <span class="post-meta-icon-text">Edited on</span> <time title="Modified: 2020-10-07 21:34:09" itemprop="dateModified" datetime="2020-10-07T21:34:09+08:00">2020-10-07</time></div><span class="post-count"><span class="post-symbolcount"><span class="post-meta-item-icon" title="Words count in article"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-file-word-line"></use></svg></span> <span title="Words count in article">2.2k</span><span class="post-meta-divider">-</span><span class="post-meta-item-icon" title="Reading time"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-timer-line"></use></svg></span> <span title="Reading time">7m</span></span></span><div class="post-classify"><span class="post-category"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-line"></use></svg></span> <span itemprop="about" itemscope itemtype="https://schema.org/Thing"><a class="category" href="/categories/MachineLearning/" style="--text-color:var(--hty-text-color)" itemprop="url" rel="index"><span itemprop="text">MachineLearning</span></a></span></span><span class="post-tag"><span class="post-meta-divider">-</span><a class="tag" href="/tags/MachineLearning/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">MachineLearning</span></a></span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content markdown-body" style="--smc-primary:#6200ee;"><h2 id="什么是决策树？"><a href="#什么是决策树？" class="headerlink" title="什么是决策树？"></a>什么是决策树？</h2><p>决策树是一种逻辑简单的机器学习算法，可用作分类，也可用作回归，属于监督学习（Supervised learning）。</p>
<p>决策树的模型表达式 f(x) 很难被写出，却很容易被画出</p>
<h3 id="决策树是一种树形结构："><a href="#决策树是一种树形结构：" class="headerlink" title="决策树是一种树形结构："></a>决策树是一种树形结构：</h3><blockquote>
<h6 id="树形结构："><a href="#树形结构：" class="headerlink" title="树形结构："></a>树形结构：</h6><p><strong>①结点+有向边</strong><br><strong>②没有回路，根结点为始、叶子结点为终</strong></p>
</blockquote>
<img src="https://img-blog.csdnimg.cn/20200424102622422.png" width="30%" loading="lazy">

<p><strong>或者这么画：</strong></p>
<img src="https://img-blog.csdnimg.cn/20200424102640336.png" width="40%" loading="lazy">


<pre><code>根节点：包含样本的全集
内部节点：对应特征属性测试
叶节点：代表决策的结果</code></pre>
<h3 id="决策树学习的步骤："><a href="#决策树学习的步骤：" class="headerlink" title="决策树学习的步骤："></a>决策树学习的步骤：</h3><ol>
<li><p><strong>特征选择</strong><br>根据信息增益的准则，筛选出跟分类结果相关性较高的特征，也就是分类能力较强的特征。</p>
</li>
<li><p><strong>决策树生成及分裂</strong><br>从根节点开始，对每个节点计算所有特征的信息增益，选择信息增益最大的特征作为节点特征，根据该特征的不同取值建立子节点；然后对每个子节点使用相同的方式生成新的子节点，直到信息增益很小或者没有特征可以选择为止。</p>
</li>
<li><p><strong>决策树剪枝</strong><br>主动去掉部分分支，防止过拟合。</p>
</li>
</ol>
<h3 id="决策树的分裂（决策）："><a href="#决策树的分裂（决策）：" class="headerlink" title="决策树的分裂（决策）："></a>决策树的分裂（决策）：</h3><img src="https://img-blog.csdnimg.cn/20200424105433997.png" width="20%" loading="lazy">

<p><strong>根据 <code>分裂的特征 x</code> 和 <code>分裂的阈值 a</code> 进行分裂，即进行一次决策。然后由判断结果决定进入哪个分支节点，直至到达叶节点处，得到分类结果。</strong></p>
<blockquote>
<p>在构建决策树模型时，我们无法得知参数数量，而是采用启发式算法。</p>
</blockquote>
<h3 id="启发式算法："><a href="#启发式算法：" class="headerlink" title="启发式算法："></a>启发式算法：</h3><ol>
<li><strong>将所有的训练数据都放在根结点中。</strong></li>
<li><strong>选择一个当前的最优决策，将根结点的数据分割成子集。</strong></li>
<li><strong>对每个子集，选择一个子集的最优决策，得到子集的子集。</strong></li>
<li><strong>递归执行，直到各个子集都有较好的分类时结束。</strong></li>
</ol>
<h3 id="最优决策："><a href="#最优决策：" class="headerlink" title="最优决策："></a>最优决策：</h3><blockquote>
<p>分类树决策的优劣用熵来衡量。</p>
</blockquote>
<img src="https://img-blog.csdnimg.cn/20200424110907282.png" width="30%" loading="lazy">



<img src="https://img-blog.csdnimg.cn/20200424111253350.png" width="30%" loading="lazy">



<h4 id="决策树的损失函数就是条件熵"><a href="#决策树的损失函数就是条件熵" class="headerlink" title="决策树的损失函数就是条件熵"></a><code>决策树的损失函数就是条件熵</code></h4><h3 id="决策树算法的分类："><a href="#决策树算法的分类：" class="headerlink" title="决策树算法的分类："></a>决策树算法的分类：</h3><ul>
<li><strong>ID3</strong></li>
<li><strong>C4.5</strong></li>
<li><strong>CART</strong></li>
</ul>
<p>ID3 算法的思路：信息增益最大化<br><code>信息增益 = 熵 - 条件熵</code></p>
<p>C4.5 算法的思路：信息增益率最大化<br><code>信息增益率 = 信息增益 / 熵</code></p>
<blockquote>
<p>ID3 算法和 C4.5算法 的区别仅在于信息增益和信息增益率。</p>
</blockquote>
<h3 id="决策树算法的优缺点："><a href="#决策树算法的优缺点：" class="headerlink" title="决策树算法的优缺点："></a>决策树算法的优缺点：</h3><ul>
<li>优点：计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特征数据。</li>
<li>缺点：可能会产生过度匹配问题。</li>
<li>适用数据类型：数值型和标称型。</li>
</ul>
<h2 id="什么是-ID3-算法？"><a href="#什么是-ID3-算法？" class="headerlink" title="什么是 $ID3$ 算法？"></a>什么是 $ID3$ 算法？</h2><p>$ID3$ 算法是构建决策树模型的一种常用方法，根据信息增益来选择特征。</p>
<h3 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h3><p>“信息熵”是度量样本集合纯度最常用的一种指标，假定当前样本集合 $D$ 中第 $k$ 类样本所占的比例为$P_k (k=1,2,…,|y|)$，则 $D$ 的信息熵定义为：</p>
<div>
    $$Ent(D)=-\sum^{|y|}_{k=1}p_klog_2p_k$$
</div>



<p>$Ent(D)$ 的值越小，则 $D$ 的纯度越高。</p>
<p>假定离散属性 $a$ 有 $V$ 个可能的取值 ${a^1,a^2, …,a^V}$ ，若使用 $a$ 来对样本集 $D$ 进行划分，则会产生 $V$ 个分支结点，其中第 $v$ 个分支结点包含了 $D$ 中所有在属性 $a$ 上取值为 $a^v$ 的样本，记为 $D^v$ 。我们可根据式（4.1）计算出 $D^v$ 的信息熵，再考虑到不同的分支结点所包含的样本数不同，给分支结点赋予权重 $|D^v|/|D|$，即样本数越多的分支结点对提升纯度的帮助越大，于是可计算出用属性 $a$ 对样本集 $D$ 进行划分所获得的“信息增益”，<strong>求和项也称为“条件熵”</strong>：</p>
<div>
    $$Gain(D,a)=Ent(D)-\sum^V_{v=1}\frac{|D^v|}{|D|}Ent(D^v)$$
</div>



<p>一般地，信息增益越大，则使用属性 $a$ 来进行划分所获得的“纯度提升”越大。因此可用信息增益来进行决策树的划分属性选择，即在决策树算法中选择属性 $a_* = arg_{a∈A}max Gain(D,a)$。</p>
<p><strong>$ID3$ 算法就是以信息增益为准则来选择划分属性。</strong></p>
<h3 id="ID3-算法的步骤："><a href="#ID3-算法的步骤：" class="headerlink" title="$ID3$ 算法的步骤："></a>$ID3$ 算法的步骤：</h3><pre><code>参数：训练集 D，特征集 A，阈值 ε
返回：决策树 T</code></pre>
<ol>
<li>若 $D$ 中全部实例同属一类 $C$，则用 $C$ 作为该结点的标注，返回 $T$。（异常处理）</li>
<li>若 $A$ 为空，则将 $D$ 中实例数最多的类 $C$ 作为该结点的标注，并返回 $T$。（异常处理）</li>
<li>计算 $A$ 中每个特征对 $D$ 的信息增益，并选择信息增益最大的特征 $a$。（最优决策）</li>
<li>如果 $a$ 带来的信息增益小于阈值 $e$，则将 $D$ 中实例数最多的类 $C$ 作为该结点的标注，并返回 $T$ 。</li>
<li>对特征 $a$ 的每个可能取值 $a_i$，将数据集 $D$ 分割为几个子集 $D_i$ 构建子节点，由结点、子结点、$a$、每个 $a_i$ 构建决策树 $T$。</li>
<li>对每个子集，以 $D_i$ 为数据集，以 $A- {a}$ 为特征集，递归调用1~5步。</li>
</ol>
<h2 id="什么是-C4-5-算法？"><a href="#什么是-C4-5-算法？" class="headerlink" title="什么是 $C4.5$ 算法？"></a>什么是 $C4.5$ 算法？</h2><h6 id="C4-5-算法是基于-ID3-算法的改良，-C4-5-算法不直接使用信息增益，而是使用“信息增益率”来选择最优划分属性。"><a href="#C4-5-算法是基于-ID3-算法的改良，-C4-5-算法不直接使用信息增益，而是使用“信息增益率”来选择最优划分属性。" class="headerlink" title="$C4.5$ 算法是基于 $ID3$ 算法的改良，$C4.5$ 算法不直接使用信息增益，而是使用“信息增益率”来选择最优划分属性。"></a>$C4.5$ 算法是基于 $ID3$ 算法的改良，$C4.5$ 算法不直接使用信息增益，而是使用“信息增益率”来选择最优划分属性。</h6><h6 id="基于-ID3-算法的优化："><a href="#基于-ID3-算法的优化：" class="headerlink" title="基于 $ID3$ 算法的优化："></a>基于 $ID3$ 算法的优化：</h6><pre><code>1) 用信息增益率来选择属性，克服了用信息增益选择属性时偏向选择取值多的属性的不足；

2) 在树构造过程中进行剪枝；

3) 能够完成对连续属性的离散化处理；

4) 能够对不完整数据进行处理。</code></pre>
<h3 id="信息增益率"><a href="#信息增益率" class="headerlink" title="信息增益率"></a>信息增益率</h3><p>信息增益准则对可取值数目较多的属性有所偏好，然而这样的决策树显然不具有泛化能力，无法对新样本进行有效预测。而 $C4.5$ 算法不直接使用信息增益，而是使用“信息增益率”来选择最优划分属性，假定当前样本集合为 $D$，信息增益率定义为：</p>
<div>
    $$Gain\_ratio(D,a)=\frac{Gain(D,a)}{IV(a)}$$
</div>



<p>其中</p>
<div>
    $$IV(a)=-\sum^V_{v=1}\frac{|D^v|}{|D|}log_2\frac{|D^v|}{|D|}$$
</div>



<p>称为属性 $a$ 的“固有值”。它的定义与信息熵类似，信息熵衡量的是样本集在类别上的混乱程度，而 <strong>固有值衡量的是样本集在某个属性上的混乱程度</strong>。若属性 $a$ 的可能取值数目 $V$ 越大，$IV(a)$ 的值通常会越大，即该属性混乱程度越高。</p>
<p>需要注意的是，信息增益率准则对可取值数目较少的属性有所偏好。因此，$C4.5$ 算法并不是直接选择信息增益率最大的候选划分属性，而是使用了一个启发式：<strong>先从候选划分属性中找出信息增益高于平均水平的属性，再从中选择增益率最高的</strong>。</p>
<h6 id="C4-5-的不足之处："><a href="#C4-5-的不足之处：" class="headerlink" title="$C4.5$ 的不足之处："></a>$C4.5$ 的不足之处：</h6><ul>
<li>$C4.5$ 生成的是多叉树，一个父节点可以有多个子节点，运算效率没有二叉树高；</li>
<li>$C4.5$ 使用了熵模型，里面有大量的对数运算。如果有连续值的属性，还涉及到排序运算，运算量很大。</li>
</ul>
<h2 id="CART-算法"><a href="#CART-算法" class="headerlink" title="$CART$ 算法"></a>$CART$ 算法</h2><p>$CART$（Classification and Regression Tree，即分类回归树算法）是一种著名的决策树学习算法，可用于分类和回归任务。</p>
<p>$CART$ 算法使用“基尼指数”来选择划分属性。</p>
<h3 id="基尼指数"><a href="#基尼指数" class="headerlink" title="基尼指数"></a>基尼指数</h3><p>假定当前样本集合 $D$ 中第 $k$ 类样本所占的比例为$P_k (k=1,2,…,|y|)$。</p>
<p>数据集 $D$ 的纯度可用基尼值来度量：</p>
<div>
    $$Gini(D)=\sum^{|y|}_{k=1}\sum_{k'≠k}p_kp_{k'}=\sum^{|y|}_{k=1}p_k(1-p_k)=1-\sum^{|y|}_{k=1}p^2_k$$
</div>



<p>直观来说，**$Gini(D)$ 反映了从数据集 $D$ 中随机抽取 $2$ 个样本，其类别标记不一致的概率**。因此，$Gini(D) $ 越小，基尼值越小，则数据集 $D$ 的纯度越高。属性 $α$ 的基尼指数定义：</p>
<div>
    $$Gini\_index(D,a)=\sum^V_{v=1}\frac{|D^v|}{|D|}Gini(D^v)$$
</div>



<p>基尼指数越小，表示使用属性 $a$ 划分后纯度的提升越大。因此，在属性集合 $A$ 中，选择基尼指数最小的属性 $a$ 作为最优划分属性，即 $a_*=arg_{a∈A}minGini_index(D,a)$。</p>
<h4 id="CART-算法中主要分为两个步骤"><a href="#CART-算法中主要分为两个步骤" class="headerlink" title="$CART$ 算法中主要分为两个步骤"></a>$CART$ 算法中主要分为两个步骤</h4><ol>
<li><p>将样本递归划分进行建树过程</p>
</li>
<li><p>用验证数据进行剪枝</p>
</li>
</ol>
<p>Reference：《机器学习》</p>
</div><div id="reward-container"><span class="hty-icon-button button-glow" id="reward-button" title="Donate" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === &quot;none&quot;) ? &quot;block&quot; : &quot;none&quot;;"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-hand-coin-line"></use></svg></span><div id="qr" style="display:none;"><div style="display:inline-block"><a href="/images/Ali-Pay.jpg"><img loading="lazy" src="/images/Ali-Pay.jpg" alt="Ali-Pay" title="Ali-Pay"></a><div><span style="color:#00A3EE"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-alipay-line"></use></svg></span></div></div><div style="display:inline-block"><a href="/images/WeChatPay.jpg"><img loading="lazy" src="/images/WeChatPay.jpg" alt="WeChat Pay" title="WeChat Pay"></a><div><span style="color:#2DC100"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wechat-pay-line"></use></svg></span></div></div></div></div><ul class="post-copyright"><li class="post-copyright-author"><strong>Post author: </strong>Giyn</li><li class="post-copyright-link"><strong>Post link: </strong><a href="http://giyn.work/posts/748a96c4/" title="决策树算法原理">http://giyn.work/posts/748a96c4/</a></li><li class="post-copyright-license"><strong>Copyright Notice: </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 "><svg class="icon"><use xlink:href="#icon-creative-commons-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-by-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-nc-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-sa-line"></use></svg></a> unless stating additionally.</li></ul><script>document.addEventListener('copy', function (event) {
  const clipboardData = event.clipboardData || window.clipboardData;
  if (!clipboardData) { return; }
  const text = window.getSelection().toString();
  if (text) {
    event.preventDefault();
    clipboardData.setData('text/plain', text + '\n\nPost author: Giyn\nPost link: http://giyn.work/posts/748a96c4/\nCopyright Notice: All articles in this blog are licensed under CC BY-NC-SA 4.0 unless stating additionally.');
  }
});</script></section></article><div class="post-nav"><div class="post-nav-item"><a class="post-nav-prev" href="/posts/3f56ccc4/" rel="prev" title="Bagging 和随机森林算法"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-left-s-line"></use></svg><span class="post-nav-text">Bagging 和随机森林算法</span></a></div><div class="post-nav-item"><a class="post-nav-next" href="/posts/c9d19075/" rel="next" title="GBDT 模型简介及数学推导"><span class="post-nav-text">GBDT 模型简介及数学推导</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-right-s-line"></use></svg></a></div></div></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2020 – 2021 </span><span class="with-love" id="animate"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-cloud-line"></use></svg></span><span class="author"> Giyn</span></div><div class="powered"><span>Powered by <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> v5.1.1</span><span class="footer-separator">|</span><span>Theme - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v1.0.0</span></div><div class="live_time"><span>本博客已运行</span><span id="display_live_time"></span><span class="moe-text">(●'◡'●)</span><script>function blog_live_time() {
  window.setTimeout(blog_live_time, 1000);
  const start = new Date('2020-09-03T00:00:00');
  const now = new Date();
  const timeDiff = (now.getTime() - start.getTime());
  const msPerMinute = 60 * 1000;
  const msPerHour = 60 * msPerMinute;
  const msPerDay = 24 * msPerHour;
  const passDay = Math.floor(timeDiff / msPerDay);
  const passHour = Math.floor((timeDiff % msPerDay) / 60 / 60 / 1000);
  const passMinute = Math.floor((timeDiff % msPerHour) / 60 / 1000);
  const passSecond = Math.floor((timeDiff % msPerMinute) / 1000);
  display_live_time.innerHTML = " " + passDay + " 天 " + passHour + " 小时 " + passMinute + " 分 " + passSecond + " 秒";
}
blog_live_time();
</script></div></footer><a class="hty-icon-button" id="goUp" aria-label="back-to-top" href="#"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-up-s-line"></use></svg><svg class="progress-circle-container" viewBox="0 0 100 100"><circle class="progress-circle" id="progressCircle" cx="50" cy="50" r="48" fill="none" stroke="#6200ee" stroke-width="2" stroke-linecap="round"></circle></svg></a><a class="popup-trigger hty-icon-button icon-search" id="search" href="javascript:;" title="Search"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-search-line"></use></svg></span></a><script>window.addEventListener("DOMContentLoaded", () => {
  // Handle and trigger popup window
  document.querySelector(".popup-trigger").addEventListener("click", () => {
    document.querySelector(".popup").classList.add("show");
    setTimeout(() => {
      document.querySelector(".search-input").focus();
    }, 100);
  });

  // Monitor main search box
  const onPopupClose = () => {
    document.querySelector(".popup").classList.remove("show");
  };

  document.querySelector(".popup-btn-close").addEventListener("click", () => {
    onPopupClose();
  });

  window.addEventListener("keyup", event => {
    if (event.key === "Escape") {
      onPopupClose();
    }
  });
});
</script><script src="/js/search/local-search.js" defer></script><div class="popup search-popup"><div class="search-header"><span class="popup-btn-close close-icon hty-icon-button"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-close-line"></use></svg></span></div><div class="search-input-container"><input class="search-input" id="local-search-input" type="text" placeholder="Searching..." value=""></div><div id="local-search-result"></div></div><script>const date = new Date();
const today = (date.getMonth() + 1) + "-" + date.getDate()
const mourn_days = ["4-4"]
if (mourn_days.includes(today)) {
  document.documentElement.style.filter = "grayscale(1)";
}</script></div><script defer src="/js/utils.js"></script><script defer src="/js/hexo-theme-yun.js"></script></body></html>