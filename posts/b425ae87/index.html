<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="theme-color" content="#6200ee"><meta name="author" content="Giyn"><meta name="copyright" content="Giyn"><meta name="generator" content="Hexo 5.1.1"><meta name="theme" content="hexo-theme-yun"><title>使用 Scrapy 爬虫框架爬取 books.toscrape.com 上书籍的相关信息 | Giyn's Blog</title><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap" media="none" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/star-markdown-css@0.1.19/dist/yun/yun-markdown.min.css"><script src="//at.alicdn.com/t/font_1140697_stqaphw3j4.js" async></script><script src="https://cdn.jsdelivr.net/npm/scrollreveal/dist/scrollreveal.min.js" defer></script><script>document.addEventListener("DOMContentLoaded", () => {
  [".post-card",".post-content img"].forEach((target)=> {
    ScrollReveal().reveal(target);
  })
});
</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/auto-render.min.js"></script><script>document.addEventListener("DOMContentLoaded", function() {
  renderMathInElement(document.body, {
    delimiters: [
      {left: "$$", right: "$$", display: true},
      {left: "$", right: "$", display: false},
      {left: "\\(", right: "\\)", display: false},
      {left: "\\[", right: "\\]", display: true}
    ]
  });
});</script><link rel="shortcut icon" type="image/svg+xml" href="/Giyn.ico"><link rel="mask-icon" href="/Giyn.ico" color="#6200ee"><link rel="alternate icon" href="/yun.ico"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="preload" href="/js/utils.js" as="script"><link rel="preload" href="/js/hexo-theme-yun.js" as="script"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><link rel="stylesheet" href="/css/hexo-theme-yun.css"><link rel="alternate" href="/atom.xml" title="Giyn's Blog" type="application/atom+xml"><script id="yun-config">
    const Yun = window.Yun || {};
    window.CONFIG = {"root":"/","title":"许继元的博客","version":"1.0.0","anonymous_image":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/avatar/none.jpg","say":{"api":"/data/sentences.json"},"local_search":{"path":"/search.xml"},"fireworks":{"colors":["102, 167, 221","62, 131, 225","33, 78, 194"]}};
  </script><script src="//at.alicdn.com/t/font_1140697_stqaphw3j4.js" async></script><meta name="description" content="此处准备使用 Scrapy 爬虫框架对 http:&#x2F;&#x2F;books.toscrape.com&#x2F;（一个专门用来被爬取的网站）上书籍的相关信息进行爬取。 相关信息包括：书名、价格、评价等级、库存量、产品编码、评价数量。  首先进行页面分析： 这里补充一下，通常现在的浏览器都会对 HTML 文本进行一定的规范化, 所以在使用 Chrome 等浏览器自带的 XPath 路径的时候, 有可能会导致读取失败。虽">
<meta property="og:type" content="article">
<meta property="og:title" content="使用 Scrapy 爬虫框架爬取 books.toscrape.com 上书籍的相关信息">
<meta property="og:url" content="http://giyn.work/posts/b425ae87/index.html">
<meta property="og:site_name" content="Giyn&#39;s Blog">
<meta property="og:description" content="此处准备使用 Scrapy 爬虫框架对 http:&#x2F;&#x2F;books.toscrape.com&#x2F;（一个专门用来被爬取的网站）上书籍的相关信息进行爬取。 相关信息包括：书名、价格、评价等级、库存量、产品编码、评价数量。  首先进行页面分析： 这里补充一下，通常现在的浏览器都会对 HTML 文本进行一定的规范化, 所以在使用 Chrome 等浏览器自带的 XPath 路径的时候, 有可能会导致读取失败。虽">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200228113739296.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200228120504292.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/2020022811392076.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200228114106814.png?1x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTk2MTc3NA==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200228114839884.png?1x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTk2MTc3NA==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200228115211302.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200228121904511.png?1x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTk2MTc3NA==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200228122502887.png?1x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTk2MTc3NA==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200228123132343.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200228124658391.png?1x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTk2MTc3NA==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200228130935435.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200228131515231.png?1x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTk2MTc3NA==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200228131721329.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200228132038589.png?1x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTk2MTc3NA==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200228132329216.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200228133429522.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/2020022813404364.png?1x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTk2MTc3NA==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200228134510487.png?1x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTk2MTc3NA==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200228140305883.png?1x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTk2MTc3NA==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/2020022814372646.png?1x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTk2MTc3NA==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200228144256189.png?1x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTk2MTc3NA==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200228145258978.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200228145735435.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/2020022815025368.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200228172613457.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200228162331690.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200228172845805.png">
<meta property="article:published_time" content="2020-09-24T00:47:53.000Z">
<meta property="article:modified_time" content="2021-01-29T03:33:42.079Z">
<meta property="article:author" content="Giyn">
<meta property="article:tag" content="WebScraper">
<meta property="article:tag" content="Scrapy">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/20200228113739296.png"><script src="/js/ui/mode.js"></script><link id="light-prism-css" rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1.20.0/themes/prism.css" media="(prefers-color-scheme: light)"><link id="dark-prism-css" rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1.20.0/themes/prism-tomorrow.css" media="(prefers-color-scheme: dark)"></head><body><script defer src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script defer src="/js/ui/fireworks.js"></script><canvas class="fireworks"></canvas><div class="container"><a class="sidebar-toggle hty-icon-button" id="menu-btn"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><div class="sidebar-toggle sidebar-overlay"></div><aside class="sidebar"><script src="/js/sidebar.js"></script><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc hty-icon-button sidebar-nav-active" data-target="post-toc-wrap" title="Table of Contents"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-list-ordered"></use></svg></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="Overview"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-passport-line"></use></svg></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info mickey-mouse"><a class="site-author-avatar" href="/about/" title="Giyn"><img width="96" loading="lazy" src="/images/avatar.png" alt="Giyn"></a><div class="site-author-name"><a href="/about/">Giyn</a></div><a class="site-name" href="/about/site.html">Giyn's Blog</a><sub class="site-subtitle"></sub><div class="site-desciption"></div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="Home"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-home-4-line"></use></svg></span></a><div class="site-state-item"><a href="/archives/" title="Archives"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-archive-line"></use></svg></span><span class="site-state-item-count">59</span></a></div><div class="site-state-item"><a href="/categories/" title="Categories"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-2-line"></use></svg></span><span class="site-state-item-count">20</span></a></div><div class="site-state-item"><a href="/tags/" title="Tags"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="site-state-item-count">40</span></a></div><a class="site-state-item hty-icon-button" href="/about/"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-open-arm-line"></use></svg></span></a></nav><hr style="margin-bottom:0.5rem"><div class="links-of-author"><a class="links-of-author-item hty-icon-button" rel="noopener" href="/atom.xml" title="RSS" target="_blank" style="color:orange"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-rss-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://github.com/Giyn" title="GitHub" target="_blank" style="color:#181717"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-github-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="mailto:giyn.jy@gmail.com" title="E-Mail" target="_blank" style="color:#8E71C1"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-mail-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="http://wpa.qq.com/msgrd?v=3&amp;uin=490601115&amp;site=qq&amp;menu=yes" title="QQ" target="_blank" style="color:#12B7F5"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-qq-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://space.bilibili.com/443380473" title="bilibili" target="_blank" style="color:#FF8EB3"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-bilibili-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://twitter.com/jiyuan_xu" title="Twitter" target="_blank" style="color:#1da1f2"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-twitter-line"></use></svg></a></div><br><a class="links-item hty-icon-button" id="toggle-mode-btn" href="javascript:;" title="Mode" style="color: #f1cb64"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-contrast-2-line"></use></svg></a></div><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A6%96%E5%85%88%E8%BF%9B%E8%A1%8C%E9%A1%B5%E9%9D%A2%E5%88%86%E6%9E%90%EF%BC%9A"><span class="toc-number">1.</span> <span class="toc-text">首先进行页面分析：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A5%E7%AC%AC%E4%B8%80%E6%9C%AC%E4%B9%A6%E4%B8%BA%E4%BE%8B%E8%BF%9B%E8%A1%8C%E5%88%86%E6%9E%90%EF%BC%9A"><span class="toc-number">2.</span> <span class="toc-text">以第一本书为例进行分析：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8E%A5%E4%B8%8B%E6%9D%A5%E4%BD%BF%E7%94%A8-XPath-Helper-%E5%92%8C-F12-%E8%A7%A3%E6%9E%90-HTML-%E9%A1%B5%E9%9D%A2%EF%BC%9A"><span class="toc-number">3.</span> <span class="toc-text">接下来使用 XPath Helper 和 F12 解析 HTML 页面：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8E%A5%E7%9D%80%E5%BC%80%E5%A7%8B%E5%88%9B%E5%BB%BA-Scrapy-%E7%88%AC%E8%99%AB%E5%B7%A5%E7%A8%8B%EF%BC%9A"><span class="toc-number">4.</span> <span class="toc-text">接着开始创建 Scrapy 爬虫工程：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E6%AD%A5%E9%AA%A4%EF%BC%9A"><span class="toc-number">5.</span> <span class="toc-text">优化步骤：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%80%E5%90%8E%E8%BF%90%E8%A1%8C%E6%95%B4%E4%B8%AA%E7%88%AC%E8%99%AB%E9%A1%B9%E7%9B%AE%EF%BC%9A"><span class="toc-number">6.</span> <span class="toc-text">最后运行整个爬虫项目：</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%8C%E6%95%B4%E6%BA%90%E4%BB%A3%E7%A0%81"><span class="toc-number">6.1.</span> <span class="toc-text">完整源代码</span></a></li></ol></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="post-block" itemscope itemtype="https://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://giyn.work/posts/b425ae87/"><span hidden itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="name" content="Giyn"><meta itemprop="description"></span><span hidden itemprop="publisher" itemscope itemtype="https://schema.org/Organization"><meta itemprop="name" content="Giyn's Blog"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">使用 Scrapy 爬虫框架爬取 books.toscrape.com 上书籍的相关信息<a class="post-edit-link" href="https://github.com/Giyn/giyn.github.io/tree/hexo/source/_posts/使用 Scrapy 爬虫框架爬取 books.toscrape.com 上书籍的相关信息.md" target="_blank" title="Edit this post" rel="noopener"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-edit-line"></use></svg></a></h1><div class="post-meta"><div class="post-time" style="display:block"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-line"></use></svg></span> <span class="post-meta-icon-text">Posted on</span> <time title="Created: 2020-09-24 08:47:53" itemprop="dateCreated datePublished" datetime="2020-09-24T08:47:53+08:00">2020-09-24</time><span class="post-meta-divider">-</span><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-2-line"></use></svg></span> <span class="post-meta-icon-text">Edited on</span> <time title="Modified: 2021-01-29 11:33:42" itemprop="dateModified" datetime="2021-01-29T11:33:42+08:00">2021-01-29</time></div><span class="post-count"><span class="post-symbolcount"><span class="post-meta-item-icon" title="Words count in article"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-file-word-line"></use></svg></span> <span title="Words count in article">1.7k</span><span class="post-meta-divider">-</span><span class="post-meta-item-icon" title="Reading time"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-timer-line"></use></svg></span> <span title="Reading time">6m</span></span></span><div class="post-classify"><span class="post-category"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-line"></use></svg></span> <span itemprop="about" itemscope itemtype="https://schema.org/Thing"><a class="category" href="/categories/WebScraper/" style="--text-color:var(--hty-text-color)" itemprop="url" rel="index"><span itemprop="text">WebScraper</span></a></span></span><span class="post-tag"><span class="post-meta-divider">-</span><a class="tag" href="/tags/WebScraper/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">WebScraper</span></a><a class="tag" href="/tags/Scrapy/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">Scrapy</span></a></span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content markdown-body" style="--smc-primary:#6200ee;"><p>此处准备使用 Scrapy 爬虫框架对 <a target="_blank" rel="noopener" href="http://books.toscrape.com/">http://books.toscrape.com/</a>（一个专门用来被爬取的网站）上书籍的相关信息进行爬取。</p>
<p><code>相关信息包括：书名、价格、评价等级、库存量、产品编码、评价数量。</code></p>
<hr>
<h3 id="首先进行页面分析："><a href="#首先进行页面分析：" class="headerlink" title="首先进行页面分析："></a>首先进行页面分析：</h3><blockquote>
<p>这里补充一下，通常现在的浏览器都会对 HTML 文本进行一定的规范化, 所以在使用 Chrome 等浏览器自带的 XPath 路径的时候, 有可能会导致读取失败。<br>虽然很多时候用 view 命令加载出的页面和浏览器打开的是一样的，但是前者是 Scrapy 爬虫下载的页面，后者是由浏览器下载的页面，有时它们是不同的。</p>
</blockquote>
<p>在进行页面分析时，使用 view 命令更加可靠：</p>
<pre><code>在命令提示符窗口输入
scrapy shell url
view(response)
然后就打开了 Scrapy 爬虫下载的页面，此时在 F12 开发者工具中看的路径就是原始路径。</code></pre>
<h3 id="以第一本书为例进行分析："><a href="#以第一本书为例进行分析：" class="headerlink" title="以第一本书为例进行分析："></a>以第一本书为例进行分析：</h3><p>首先输入 <code>scrapy shell http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html</code><br><img src="https://img-blog.csdnimg.cn/20200228113739296.png" alt="在这里插入图片描述" loading="lazy"></p>
<blockquote>
<p>运行这条命令后，scrapy shell 会使用 URL 参数构造一个 Request 对象，并提交给 Scrapy 引擎，页面下载完成后，程序进入 Scrapy 终端，在此环境中已经创建好了一些变量（对象和函数），我们可以在这里调试爬取代码。</p>
</blockquote>
<p>状态码为 200，表示请求成功：</p>
<img src="https://img-blog.csdnimg.cn/20200228120504292.png" width="60%" loading="lazy">

<p>然后输入 <code>view(response)</code>：</p>
<img src="https://img-blog.csdnimg.cn/2020022811392076.png" width="50%" loading="lazy">



<p>然后就自动打开页面了：</p>
<p><img src="https://img-blog.csdnimg.cn/20200228114106814.png?1x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTk2MTc3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<h3 id="接下来使用-XPath-Helper-和-F12-解析-HTML-页面："><a href="#接下来使用-XPath-Helper-和-F12-解析-HTML-页面：" class="headerlink" title="接下来使用 XPath Helper 和 F12 解析 HTML 页面："></a>接下来使用 XPath Helper 和 F12 解析 HTML 页面：</h3><p>首先是书名：</p>
<p><img src="https://img-blog.csdnimg.cn/20200228114839884.png?1x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTk2MTc3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<p>在 Scrapy 终端里测试一下：</p>
<p><img src="https://img-blog.csdnimg.cn/20200228115211302.png" alt="在这里插入图片描述" loading="lazy"></p>
<blockquote>
<p><strong>extract() 与 extract_first() 区别：</strong><br>extract() 返回的所有数据，存在一个 list 里。<br>extract_first() 返回的是一个 string，是 extract() 结果中第一个值。</p>
</blockquote>
<hr>
<p>接下来是价格：</p>
<p><img src="https://img-blog.csdnimg.cn/20200228121904511.png?1x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTk2MTc3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<hr>
<p>然后是评价等级：</p>
<p><img src="https://img-blog.csdnimg.cn/20200228122502887.png?1x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTk2MTc3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<p>我们用正则表达式去除字符串中的 <code>star-rating</code>：</p>
<p><img src="https://img-blog.csdnimg.cn/20200228123132343.png" alt="在这里插入图片描述" loading="lazy"></p>
<hr>
<p>接下来是库存量：</p>
<p><img src="https://img-blog.csdnimg.cn/20200228124658391.png?1x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTk2MTc3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<p>我们依然使用正则表达式对库存量进行提取：</p>
<p><img src="https://img-blog.csdnimg.cn/20200228130935435.png" alt="在这里插入图片描述" loading="lazy"></p>
<p><strong>这里我们会发现，按照我们直接分析的 XPath 是提取不到内容的，我们得删去 tbody 标签，为什么呢？</strong></p>
<p>因为浏览器本身自动为 table 新增了 tbody 标签内容，但是在 xpath 中是不需要的（试试看把 tbody 标签去掉，依然表示对应的信息），需要在进行 xpath 查询之时移除掉。</p>
<hr>
<p>然后是产品编码：</p>
<p><img src="https://img-blog.csdnimg.cn/20200228131515231.png?1x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTk2MTc3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<p>同理，我们可以这样提取：</p>
<p><img src="https://img-blog.csdnimg.cn/20200228131721329.png" alt="在这里插入图片描述" loading="lazy"></p>
<hr>
<p>最后是评价数量：</p>
<p><img src="https://img-blog.csdnimg.cn/20200228132038589.png?1x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTk2MTc3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<p>同理，我们可以这样提取：</p>
<p><img src="https://img-blog.csdnimg.cn/20200228132329216.png" alt="在这里插入图片描述" loading="lazy"></p>
<hr>
<p>至此，我们已经分析完了一本书的页面，接下来我们考虑一下如何<strong>获取一个页面所有书籍的链接以及获取下一页的链接</strong>。</p>
<hr>
<p>首先我们<strong>使用 fetch 命令下载书籍列表页面</strong>，然后<strong>用 view 命令打开页面进行分析</strong>：</p>
<p><img src="https://img-blog.csdnimg.cn/20200228133429522.png" alt="在这里插入图片描述" loading="lazy"></p>
<p>经过分析，一个页面所有书籍的链接如下：</p>
<p><img src="https://img-blog.csdnimg.cn/2020022813404364.png?1x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTk2MTc3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<p>接下来分析下一页的链接：</p>
<p><img src="https://img-blog.csdnimg.cn/20200228134510487.png?1x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTk2MTc3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<hr>
<p>然后我们使用 LinkExtractor 提取这些链接：</p>
<blockquote>
<p>因为 href 中的链接跟该站点有联系，直接获取出来的不是绝对 URL，需要拼接计算。<br>如 catalogue/page-2.html 是标签中的内容，而正确地址为 <a target="_blank" rel="noopener" href="http://books.toscrape.com/catalogue/page-2.html">http://books.toscrape.com/catalogue/page-2.html</a></p>
</blockquote>
<p>我们分析一下如何提取一个页面中所有书的绝对链接：</p>
<p><img src="https://img-blog.csdnimg.cn/20200228140305883.png?1x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTk2MTc3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<p>接下来用 Scrapy 终端测试一下：</p>
<blockquote>
<p>这里有个细节要注意，在使用双重引号的时候，要么外面是双引号，里面是单引号；要么反过来。否则就会报错：SyntaxError: invalid syntax</p>
<p><img src="https://img-blog.csdnimg.cn/2020022814372646.png?1x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTk2MTc3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
</blockquote>
<p>然后用 Scrapy 终端测试下一页的链接：</p>
<p><img src="https://img-blog.csdnimg.cn/20200228144256189.png?1x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTk2MTc3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<p><strong>这里详细分析一下这些对象：</strong></p>
<ul>
<li><p>le 是 LinkExtractor 对象，起到选择器作用，定义选取规则。</p>
</li>
<li><p>links 是 le 调用 extract_links 方法，传入当前页面 response，在当前页面中根据 le 规则寻找 links，返回 Link 对象组成的列表。</p>
</li>
<li><p>links[0] 是一个 Link 对象。</p>
</li>
<li><p>links[0].url 是对象的一个属性，即我们要的绝对 URL 地址（无需再拼接计算）。</p>
</li>
</ul>
<hr>
<h3 id="接着开始创建-Scrapy-爬虫工程："><a href="#接着开始创建-Scrapy-爬虫工程：" class="headerlink" title="接着开始创建 Scrapy 爬虫工程："></a>接着开始创建 Scrapy 爬虫工程：</h3><p>此处使用 Pycharm 实现，首先在 Pycharm 创建一个新的项目 MyScrapy：</p>
<img src="https://img-blog.csdnimg.cn/20200228145258978.png" width="60%" loading="lazy">

<p>接下来打开 Pycharm 的终端 Terminal，输入 <code>scrapy startproject books</code> 创建一个 Scrapy 爬虫项目：</p>
<img src="https://img-blog.csdnimg.cn/20200228145735435.png" width="60%" loading="lazy">

<p>然后进入 books 目录，输入 <code>scrapy genspider books_spider books.toscrape.com </code>创建 Spider 文件以及 Spider 类：</p>
<img src="https://img-blog.csdnimg.cn/2020022815025368.png" width="60%" loading="lazy">


<p>在实现 Spider 之前，先定义封装书籍信息的 Item 类，在 items.py 中添加如下代码：</p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># 书籍项目</span>
<span class="token keyword">class</span> <span class="token class-name">BooksItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 书名</span>
    price <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 价格</span>
    review_rating <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 评价等级</span>
    review_num <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 评价数量</span>
    upc <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 产品编码</span>
    stock <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 库存量</span></code></pre>


<p>接下来我们在爬虫类中要实现两个页面解析函数，一个是每一页的页面解析函数，一个是每本书的页面解析函数，打开 books.py，根据我们前面的分析，编辑代码如下：</p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># -*- coding: utf-8 -*-</span>
<span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>linkextractors <span class="token keyword">import</span> LinkExtractor
<span class="token keyword">from</span> <span class="token punctuation">.</span><span class="token punctuation">.</span>items <span class="token keyword">import</span> BooksItem  <span class="token comment"># ..表示上级目录</span>

<span class="token keyword">class</span> <span class="token class-name">BooksSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'books'</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'books.toscrape.com'</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://books.toscrape.com/'</span><span class="token punctuation">]</span>

    <span class="token comment"># 每一页的页面解析函数</span>
    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 提取当前页面所有书的url</span>
        le <span class="token operator">=</span> LinkExtractor<span class="token punctuation">(</span>restrict_xpaths<span class="token operator">=</span><span class="token string">'//article[@class="product_pod"]'</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> link <span class="token keyword">in</span> le<span class="token punctuation">.</span>extract_links<span class="token punctuation">(</span>response<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>url<span class="token operator">=</span>link<span class="token punctuation">.</span>url<span class="token punctuation">,</span> callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse_book<span class="token punctuation">)</span>

        <span class="token comment"># 提取下一页的url</span>
        le <span class="token operator">=</span> LinkExtractor<span class="token punctuation">(</span>restrict_xpaths<span class="token operator">=</span><span class="token string">'//ul[@class="pager"]/li[@class="next"]/a'</span><span class="token punctuation">)</span>
        links <span class="token operator">=</span> le<span class="token punctuation">.</span>extract_links<span class="token punctuation">(</span>response<span class="token punctuation">)</span>
        <span class="token keyword">if</span> links<span class="token punctuation">:</span>
            next_url <span class="token operator">=</span> links<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>url
            <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>url<span class="token operator">=</span>next_url<span class="token punctuation">,</span> callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span>

    <span class="token comment"># 每一本书的页面解析函数</span>
    <span class="token keyword">def</span> <span class="token function">parse_book</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        book <span class="token operator">=</span> BooksItem<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 将信息存入BooksItem对象</span>
        book<span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">]</span> <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//div[@class="col-sm-6 product_main"]/h1/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
        book<span class="token punctuation">[</span><span class="token string">'price'</span><span class="token punctuation">]</span> <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//p[@class="price_color"]/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
        book<span class="token punctuation">[</span><span class="token string">'review_rating'</span><span class="token punctuation">]</span> <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//div[@class="col-sm-6 product_main"]/p[3]/@class'</span><span class="token punctuation">)</span> \
            <span class="token punctuation">.</span>re_first<span class="token punctuation">(</span><span class="token string">'star-rating ([A-Za-z]+)'</span><span class="token punctuation">)</span>  <span class="token comment"># \是续行符</span>
        book<span class="token punctuation">[</span><span class="token string">'stock'</span><span class="token punctuation">]</span> <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//table[@class="table table-striped"]//tr[6]/td/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>re_first<span class="token punctuation">(</span><span class="token string">'\((\d+) available\)'</span><span class="token punctuation">)</span>
        book<span class="token punctuation">[</span><span class="token string">'upc'</span><span class="token punctuation">]</span> <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//table[@class="table table-striped"]//tr[1]/td/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
        book<span class="token punctuation">[</span><span class="token string">'review_num'</span><span class="token punctuation">]</span> <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//table[@class="table table-striped"]//tr[7]/td/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">yield</span> book</code></pre>


<hr>
<h3 id="优化步骤："><a href="#优化步骤：" class="headerlink" title="优化步骤："></a>优化步骤：</h3><p>接下来配置文件 settings.py，使用 FEED_EXPORT_FIELDS 指定各列的次序：</p>
<pre class="language-python" data-language="python"><code class="language-python">FEED_EXPORT_FIELDS<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'upc'</span><span class="token punctuation">,</span><span class="token string">'name'</span><span class="token punctuation">,</span><span class="token string">'price'</span><span class="token punctuation">,</span><span class="token string">'stock'</span><span class="token punctuation">,</span><span class="token string">'review_rating'</span><span class="token punctuation">,</span><span class="token string">'review_num'</span><span class="token punctuation">]</span></code></pre>


<p>另外，评价等级字段的值是 One、Two、Three…… 这样的英语单词，我们可以将它们改为阿拉伯数字，下面实现一个 Item Pipeline，将单词映射到数字。在 pipelines.py 中实现 BookPipeline，代码如下：</p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">BooksPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    review_rating_map <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
        <span class="token string">'One'</span><span class="token punctuation">:</span>  <span class="token number">1</span><span class="token punctuation">,</span>
        <span class="token string">'Two'</span><span class="token punctuation">:</span>  <span class="token number">2</span><span class="token punctuation">,</span>
        <span class="token string">'Three'</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">,</span>
        <span class="token string">'Four'</span><span class="token punctuation">:</span> <span class="token number">4</span><span class="token punctuation">,</span>
        <span class="token string">'Five'</span><span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">,</span>
        <span class="token punctuation">&#125;</span>
    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>item<span class="token punctuation">,</span>spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        rating <span class="token operator">=</span> item<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'review_rating'</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> rating<span class="token punctuation">:</span>
            item<span class="token punctuation">[</span><span class="token string">'review_rating'</span><span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>review_rating_map<span class="token punctuation">[</span>rating<span class="token punctuation">]</span>
        <span class="token keyword">return</span> item</code></pre>


<p>然后在配置文件 settings.py 中启用 BooksPipeline：</p>
<pre class="language-python" data-language="python"><code class="language-python">ITEM_PIPELINES <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token string">'books.pipelines.BooksPipeline'</span><span class="token punctuation">:</span> <span class="token number">300</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span> <span class="token comment"># books是 Scrapy爬虫项目的名字</span></code></pre>

<hr>
<h3 id="最后运行整个爬虫项目："><a href="#最后运行整个爬虫项目：" class="headerlink" title="最后运行整个爬虫项目："></a>最后运行整个爬虫项目：</h3><p>在 Pycharm 终端输入 <code>scrapy crawl books_spider -o books.csv --nolog</code>：</p>
<blockquote>
<p>这里加上 - -nolog 就可以不显示运行日志</p>
</blockquote>
<img src="https://img-blog.csdnimg.cn/20200228172613457.png" width="60%" loading="lazy">



<img src="https://img-blog.csdnimg.cn/20200228162331690.png" width="60%" loading="lazy">



<img src="https://img-blog.csdnimg.cn/20200228172845805.png" width="60%" loading="lazy">


<p>至此，整个爬虫项目就完成了。</p>
<hr>
<h4 id="完整源代码"><a href="#完整源代码" class="headerlink" title="完整源代码"></a><a target="_blank" rel="noopener" href="https://github.com/Giyn/PythonSpider/tree/master/MyScrapyBooks/books">完整源代码</a></h4></div><div id="reward-container"><span class="hty-icon-button button-glow" id="reward-button" title="Donate" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === &quot;none&quot;) ? &quot;block&quot; : &quot;none&quot;;"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-hand-coin-line"></use></svg></span><div id="qr" style="display:none;"><div style="display:inline-block"><a href="/images/Ali-Pay.jpg"><img loading="lazy" src="/images/Ali-Pay.jpg" alt="Ali-Pay" title="Ali-Pay"></a><div><span style="color:#00A3EE"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-alipay-line"></use></svg></span></div></div><div style="display:inline-block"><a href="/images/WeChatPay.jpg"><img loading="lazy" src="/images/WeChatPay.jpg" alt="WeChat Pay" title="WeChat Pay"></a><div><span style="color:#2DC100"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wechat-pay-line"></use></svg></span></div></div></div></div><ul class="post-copyright"><li class="post-copyright-author"><strong>Post author: </strong>Giyn</li><li class="post-copyright-link"><strong>Post link: </strong><a href="http://giyn.work/posts/b425ae87/" title="使用 Scrapy 爬虫框架爬取 books.toscrape.com 上书籍的相关信息">http://giyn.work/posts/b425ae87/</a></li><li class="post-copyright-license"><strong>Copyright Notice: </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 "><svg class="icon"><use xlink:href="#icon-creative-commons-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-by-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-nc-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-sa-line"></use></svg></a> unless stating additionally.</li></ul><script>document.addEventListener('copy', function (event) {
  const clipboardData = event.clipboardData || window.clipboardData;
  if (!clipboardData) { return; }
  const text = window.getSelection().toString();
  if (text) {
    event.preventDefault();
    clipboardData.setData('text/plain', text + '\n\nPost author: Giyn\nPost link: http://giyn.work/posts/b425ae87/\nCopyright Notice: All articles in this blog are licensed under CC BY-NC-SA 4.0 unless stating additionally.');
  }
});</script></section></article><div class="post-nav"><div class="post-nav-item"><a class="post-nav-prev" href="/posts/e4ca6198/" rel="prev" title="模拟 Ajax 请求爬取 4000 部豆瓣电影"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-left-s-line"></use></svg><span class="post-nav-text">模拟 Ajax 请求爬取 4000 部豆瓣电影</span></a></div><div class="post-nav-item"><a class="post-nav-next" href="/posts/534e73ee/" rel="next" title="爬取 b 站视频的名称、地址、简介、观看次数、弹幕数量及发布时间"><span class="post-nav-text">爬取 b 站视频的名称、地址、简介、观看次数、弹幕数量及发布时间</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-right-s-line"></use></svg></a></div></div></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2020 – 2021 </span><span class="with-love" id="animate"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-cloud-line"></use></svg></span><span class="author"> Giyn</span></div><div class="powered"><span>Powered by <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> v5.1.1</span><span class="footer-separator">|</span><span>Theme - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v1.0.0</span></div><div class="live_time"><span>本博客已运行</span><span id="display_live_time"></span><span class="moe-text">(●'◡'●)</span><script>function blog_live_time() {
  window.setTimeout(blog_live_time, 1000);
  const start = new Date('2020-09-03T00:00:00');
  const now = new Date();
  const timeDiff = (now.getTime() - start.getTime());
  const msPerMinute = 60 * 1000;
  const msPerHour = 60 * msPerMinute;
  const msPerDay = 24 * msPerHour;
  const passDay = Math.floor(timeDiff / msPerDay);
  const passHour = Math.floor((timeDiff % msPerDay) / 60 / 60 / 1000);
  const passMinute = Math.floor((timeDiff % msPerHour) / 60 / 1000);
  const passSecond = Math.floor((timeDiff % msPerMinute) / 1000);
  display_live_time.innerHTML = " " + passDay + " 天 " + passHour + " 小时 " + passMinute + " 分 " + passSecond + " 秒";
}
blog_live_time();
</script></div></footer><a class="hty-icon-button" id="goUp" aria-label="back-to-top" href="#"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-up-s-line"></use></svg><svg class="progress-circle-container" viewBox="0 0 100 100"><circle class="progress-circle" id="progressCircle" cx="50" cy="50" r="48" fill="none" stroke="#6200ee" stroke-width="2" stroke-linecap="round"></circle></svg></a><a class="popup-trigger hty-icon-button icon-search" id="search" href="javascript:;" title="Search"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-search-line"></use></svg></span></a><script>window.addEventListener("DOMContentLoaded", () => {
  // Handle and trigger popup window
  document.querySelector(".popup-trigger").addEventListener("click", () => {
    document.querySelector(".popup").classList.add("show");
    setTimeout(() => {
      document.querySelector(".search-input").focus();
    }, 100);
  });

  // Monitor main search box
  const onPopupClose = () => {
    document.querySelector(".popup").classList.remove("show");
  };

  document.querySelector(".popup-btn-close").addEventListener("click", () => {
    onPopupClose();
  });

  window.addEventListener("keyup", event => {
    if (event.key === "Escape") {
      onPopupClose();
    }
  });
});
</script><script src="/js/search/local-search.js" defer></script><div class="popup search-popup"><div class="search-header"><span class="popup-btn-close close-icon hty-icon-button"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-close-line"></use></svg></span></div><div class="search-input-container"><input class="search-input" id="local-search-input" type="text" placeholder="Searching..." value=""></div><div id="local-search-result"></div></div><script>const date = new Date();
const today = (date.getMonth() + 1) + "-" + date.getDate()
const mourn_days = ["4-4"]
if (mourn_days.includes(today)) {
  document.documentElement.style.filter = "grayscale(1)";
}</script></div><script defer src="/js/utils.js"></script><script defer src="/js/hexo-theme-yun.js"></script></body></html>